---
title: "CUNY SPS DATA 605 HW9"
author: "Chinedu Onyeka"
date: "2023-10-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<center> **Problem 1 - Pg 363 Ex. 11**</center> 
The price of one share of stock in the Pilsdorff Beer Company is given by $Y_n$ on the $n$th day of the year. Finn observes that the differences $X_n = Y_{n+1} - Y_n$ appear to be independent random variables with a common distribution having mean $\mu = 0$ and variance $\sigma^2 = 1/4$. If $Y_1 = 100$, estimate the probability that $Y_{365}$ is  

a. $\ge 100$
b. $\ge 110$
c. $\ge 120$  

</br>  
**Solution 1**  
Since $X_n$ is an independent random variable, then its sum $S_n$ is normally distributed. 
```{r}
std_dev = sqrt(365 * (1/4))
mean_value = 0
```

</br>
*Solution 1(a); $Y_{365} \geq$ 100*  
Since $S_n$ is normally distributed with mean $0$ and normal distribution is symmetric, exactly half of values will be greater than mean. Alternatively:  
```{r}
prob_greater_100 <- pnorm(100 - 100, mean = mean_value, sd = std_dev, lower.tail = FALSE)
prob_greater_100
```
</br>

*Solution 1(b); $Y_{365} \geq$ 110*
```{r}
prob_greater_110 <- round(pnorm(110 - 100, mean = mean_value, sd = std_dev, lower.tail = FALSE), 4)
prob_greater_110
```
</br>

*Solution 1(c);  $Y_{365} \geq$ 120*
```{r}
prob_greater_120 <- round(pnorm(120 - 100, mean = mean_value, sd = std_dev, lower.tail = FALSE), 4)
prob_greater_120
```
</br>
<center> **Problem 2 - Binomial Distribution**</center>  
Calculate the expected value and variance of the binomial distribution using the moment generating function.  

</br>
**Solution 2** 

For the binomial distribution, the probability mass function (PMF) is given by: $P(X=k) = {n \choose k} p^k q^{n-k}$
where $q=1-p$.  

The moment generating function is given as: $M_X(t)=(q+pe^t)^n$.  

The first moment is $M'_X(t) = n(q+pe^t)^{n-1}pe^t$ which is the first derivative of $M_X(t)$ above.  

The expected value is the first moment evaluated at $t=0$, therefore:  

$$
\begin{split}
E(X)=M'_X(0) &= n(q+pe^0)^{n-1}pe^0\\
&= n(q+p)^{n-1}p\\
&= np(1-p+p)^{n-1}\\
&= np(1)^{n-1}\\
&=np
\end{split}
$$
Therefore, the expected value of the Bionomial distribution is $E(X) = np$.  

The variance is given by: $Var(X)=E(X^2)-E(X)^2$; where $E(X^2)$ is the second derivative of the moment generating function and $E(X)^2$ is the square of the first derivative of the moment generating function which is also the square of the expected value when evaluated at $t=0$.  

The second moment is $M''_X(t) = n(n-1)(q+pe^t)^{n-2}p^2 e^{2t}+n(q+pe^t)^{n-1}pe^t$. second order derivative of $M_X(t)$

Evaluating the second moment at $t=0$:

$$
\begin{split}
E(X^2)=M''_X(0) &= n(n-1)(q+pe^0)^{n-2}p^2 e^0+n(q+pe^0)^{n-1}pe^0\\
&= n(n-1)(1-p+p)^{n-2}p^2+n(1-p+p)^{n-1}p\\
&= n(n-1)p^2+np
\end{split}
$$

Since, the variance is $Var(X)=E(X^2)-E(X)^2$, substituting the values gives:

$$
\begin{split}
Var(X) &= n(n-1)p^2+np-n^2p^2 \\
&= np((n-1)p+1-np) \\
&= np(np-p+1-np) \\
&= np(1-p) \\
&= npq
\end{split}
$$
Therefore, we see that $Var(X) = npq$ for a binomial probability distribution.  

</br>  
<center> **Problem 3 - Exponential Distribution**</center>  
Calculate the expected value and variance of the exponential distribution using the moment generating function.

</br>
**Solution 3**

The probability of the exponential distribution is given by, $f(x)=\lambda e^{-\lambda x}$.  
Also, the moment generating function is $M_X(t)=\frac{\lambda}{\lambda-t}, t<\lambda$.

The first moment is, $M'_X(t) = \frac{\lambda}{(\lambda-t)^2}$ and the second moment is given by: $M''_X(t) = \frac{2\lambda}{(\lambda-t)^3}$.

To get the expected value, we evaluate the first moment at $t=0$:

$$
\begin{split}
E(X)=M'_X(0) &= \frac{\lambda}{(\lambda-0)^2} \\
&= \frac{\lambda}{\lambda^2}\\
&= \frac{1}{\lambda}
\end{split}
$$

The variance is given by: $Var(X)=E(X^2)-E(X)^2$; where $E(X^2)$ is the second derivative of the moment generating function and $E(X)^2$ is the square of the first derivative of the moment generating function which is also the square of the expected value when evaluated at $t=0$. Evaluating the variance function for where $t=0$:

$$
\begin{split}
Var(X) = E(X^2)-E(X)^2 &= M''_X(0)-M'_X(0)^2 \\
&=\frac{2\lambda}{(\lambda-0)^3} - \frac{1}{\lambda^2}\\
&=\frac{2\lambda}{\lambda^3} - \frac{1}{\lambda^2}\\
&=\frac{2}{\lambda^2} - \frac{1}{\lambda^2}\\
&=\frac{1}{\lambda^2}
\end{split}
$$

Hence, we get the expected value and variance for exponential probability distribution as $E(X)=1/\lambda$ and $Var(X)=1/\lambda^2$ respectively.
